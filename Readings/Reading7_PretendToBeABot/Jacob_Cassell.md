#Reading 7 Response
In his interview with Clara Herrmann, Sebastian Schmieg made some bold assertions about the progression of mankind in our digital society, and hinted at some scary implications of this. Schmieg kept coming back to his point that, because humans in Capitalist society must be as efficient as possible, humans are becoming equivalent to software extensions and this makes humans more expendable than ever. I think it is an absolutely terrifying thought that humanity might be moving towards reducing large portions of people to being no more useful than software. Rather, these people are treated as software by a system that has no integrity or accountability when it comes to their needs as outlined by Maslow’s Hierarchy. I also think it to be the next logical progression for humanity to take.
It has already begun with Uber and Fiverr and even sites like Etsy and ebay where all they do is connect pieces of “software” to consumers. Not to mention how often during the span of a day a user might have to tell a computer that the user is “not a robot.” And there are more humans on Earth than there have ever been at one time. In history, humans have naturally formed themselves into caste systems, often to the detriment of their own rights and liberties, or at least, it has been the dominant form of rule for most of human history. This shift in caste structure is a good idea of what might happen if tech and Capitalism keep evolving in this way.
It is especially frightening to think of these possibilities in conjunction with the ideas from the article, Moving Towards a Poetics of Artificial Superintelligence, by Nora Khan. The idea ASIs would work with data and software to achieve their goals and they would already act amorally. If the entirety of the human world was employed through a sharing economy with an Artificial Superintelligence at the helm, who knows what could happen. But it would be entirely possible for humans acting as bits of software to have their needs as outlined by Maslow’s Hierarchy ignored and thought of as an inconvenience. I am reminded of the Mike Judge film, Idiocracy, during which a stock dropping automatically laid off millions of employees overnight. Such an occurrence could be a catastrophe for humans, but for the Superintelligence, it would be business as usual.
Personally, this scares me because I do not want my fate in the hands of a machine, and I do not want to be part of a massive collective that behaves predictably and can be eliminated at the drop of a hat for the greater good. But this scares me the most because I like to think of myself as unique and special with inherent value due to the fact that I am a human being. Being reduced to something so interchangeable as software makes me feel small and insignificant. It makes me want to buy a “dumb phone” and go camping so I can be less a part of the digital world.
