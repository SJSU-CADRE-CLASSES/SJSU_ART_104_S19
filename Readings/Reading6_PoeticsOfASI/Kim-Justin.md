## Poetics of ASI

**AI outside of human construction?**



_This is just one exercise that we could do to imagine a future in which we are irrelevant bystanders. A world in which we kneel at the outer wall of a kingdom we’re locked out of. This would be the world in which artificial superintelligence, or ASI, has emerged.
ASI is an intellect that exceeds all the smartest, most capable human beings in every field, in abstract reasoning and social manoeuvring and creative experimentation, by unfathomable degrees. This intelligence could take form as a seed AI, a few cognitive steps above a person, or it can be a mature superintelligence that soars miles above, beyond, the blip, the dot of us, collected.
ASI would only come one step after an artificial general intelligence (AGI), or an AI that models all aspects of human intelligence, is realised. An AGI can do anything a human can, including learn, reason and improve. Of course, neither AGI nor ASI have been achieved, but to hear the great scientific minds of the world speak, both end states are fast approaching, and soon. The question isn’t whether they are coming, but when.
ASI will function in ways we can’t and won’t understand, but it won’t necessarily be unfriendly. Friendly, unfriendly, moral and immoral — these concepts won’t apply. An ASI would be motivated by interpretations of the world within cognitive frameworks that we can’t access. To an ASI, humanity could appear as a large, sluggish mass that barely moves. Cyberneticist Kevin Warwick asks, ‘How can you reason, how can you bargain, how can you understand how [a] machine is thinking when it’s thinking in dimensions you can’t conceive of?’
The act of imagining the inner life of artificial intelligence could force a language better suited than what we have now. We rarely linger on how AIs see us, but a poet could help us speculate on the heart, mind, sentiments and inner life of an AGI or ASI. The very exercise of conceiving what our minds could look like stretched to their furthest capacities is an important push of our current cognitive abilities. Imagining cognition greater than ours could deepen our own cognition.
As our metaphors curve towards the amoral, to celebrate the beauty of systems, we could end up feeling more human, more rooted, more like ourselves. This has always been the function of the ‘Other’: alien, AI, or God. Future-casting can be exhilarating and life-affirming. We move from surrender over into awe and wonder, and finally, alertness. Speaking about superintelligence in non-anthropomorphic terms seems like a crucial, precious practice to start right away. The ability to anticipate and think outside ourselves will only help us in future encounters. We will have to rely on our speculative strengths. We must reorient outwards._


~~Nora N. Khan first starts off this text by asking the reader to imagine what form an ASI would take in our heads. Does it take the form of a human with skinnier lengthier features or is it a voice that we hear in the space around us. From movies, I would just imagine a robot that walks on two feet like a human. When imagining these forms, we don’t get very far from what we know. Her interpretation of an alien is something that is large but small is singular but plural, communicated through different ends of emotion and every night it dies and is resurrected in the morning. Then she proceeds to show us a picture of what the alien she described looked like? I’m not sure if the illustrations are supposed to be her imagined ASI system or aesthetics drawings to the text.
For some people imagining a world with ASI as a real possibility is horrifying and “aesthetically repulsive” because their mind automatically goes to a place of world destruction. I used to think that before reading this text. All of the theories mentioned are very creative and are scenarios I wouldn’t have ever sat down and thought about willingly because well it’s scary to think about a world where humans aren’t the main superintelligence. To not be afraid of the unknown future we have to try to understand it and that feels strange to be trying to understand something that is not yet here. But thinking about ASI before it exists provides us with spaces of new ways of thinking and feeling. Rationally, she points out that an ASI with world domination as a primary goal wouldn’t be a very “productive or fun mode”. In order to stray away from this destructive threating ASI, we must stop anthropomorphizing it. Which means to stop imagining it with human form and personality. “Think of an AI as a force of nature like a star system or hurricane – something strong, but indifferent. If its main goal is to win at chess it will be ruthless in achieving that goal but is limited to the chessboard. But if the AI’s goal is something larger in the physically world, we must be very specific about the goals we give it.”\
That quote made me feel better about the very idea of an ASI future and I’ve always thought well it’s up to us to program them so if we didn’t want them to turn bad they wouldn’t right? I rethought this when I read the Sovereign section where the example of a satiation in which in an ASI is to make a decision for the greater good and humans are not favored. “Even if we made the sovereign, its choices have nothing to do with us.” I feel as though no matter what the goal of the ASI is they can grow and improve on that idea and it could possibly change and if we keep pushing the Earth to extinction as we are doing now, ASI will be the species to continue to sustain the Earth and we will no longer be needed.~~
