Nora Khan does a thorough job of taking her readers through the fruition, development and future existence of AI, AGI and ASI in her piece Towards a Poetics of Artificial Superintelligence: Symbolic language can help us grasp the nature and power of what is coming.   Khan simplifies the reader perception of artificial intelligence by first setting a scene in which requires the reader to envision an alien.  She relies on the antiquated idea that we naturally associate aliens with physical similarities to that of humans, however intellectually, we tend to attribute extreme intelligence to extraterrestrial beings, incomparable to the abilities of humans.  Khan then takes readers a step further into the AI realm relating our perceptions of aliens to that of AI, AGI and ASI.  By progressing from aliens to AI and finding a way to relate the two, Khan successfully begins to break down readers’ preexisting negative connotations in relation to AI. 
	Khan emphasizes that often when thinking about anything AI related,  we as a society correlate it to “Dooms Day” or some version of ending mankind.  While this is true, I personally never gave it much thought.  After delving further into Khan’s writing, she strategically imparts the facts and differences between AI and human thinking.  Something I found particularly compelling was her presentation of the fact that human cognition includes built-in impulses that limit what we are willing to do to accomplish our goals, while AI lacks these very impulses which allows for AI to accomplish more goals (Khan 2015, 6).   I do think this an important point.  First and foremost, this point revisits what essentially associates the “Dooms Day” ideas to the presence of AI.  The simple fact that AI is able to accomplish more because it lacks limitations associated to moral standings and human impulses is a bit alarming.  If we were to imagine a human who was willing to do anything to reach their goals despite morals or human impulses, naturally we would think they were a terrible person who lacked empathy amongst other things.  So why then would it be okay for a machine to do so?  While one might argue that removing emotions from the equation could infect improve success rates in regards to accomplishing goals, It’s my opinion that this doesn’t necessarily mean it would be good.  
	Moving on, Khan goes on to stress the importance of specificity when assigning AI goals.  This, according to Khan and perhaps common sense, correlates with the fact that AI lacks human-like impulses and therefore will do any and all possible options in order to reach its assigned task or goal.  Once again, this point only makes it easy to attribute negative connotations to AI.  I’m thinking Will Smith’s life experiences in I, Robot.  
	While I appreciated the arguments and facts presented in Khan’s writing, moving forward I still have my reservations about heavily relying on AI, ASG, and ASI.  Even with the most strict parameters,  I still believe AI will find a way to evolve to the point where humankind is essentially unnecessary.  Any environment in which that is plausible is obviously not in my best interest, let alone the best interest of mankind.  After all, this is kind of already prevalent in the workforce.  The first thing that comes to mind are machines doing human jobs like eliminating clerks at grocery stores in favor of self check-outs or even machines that take the place of an agent when paying for toll or parking.  Perhaps I can’t fathom the bigger picture or a life where humans aren’t the central intelligence like Khan points out, but in my opinion, AI is in fact like a child cradling an undetonated bomb (Khan 2015, 6). 
	
