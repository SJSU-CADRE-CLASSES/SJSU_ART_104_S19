Nora N. Khan first starts off this text by asking the reader to imagine what form an ASI would take in our heads. Does it take the form of a human with skinnier lengthier features or is it a voice that we hear in the space around us. From movies, I would just imagine a robot that walks on two feet like a human. When imagining these forms, we don’t get very far from what we know. Her interpretation of an alien is something that is large but small is singular but plural, communicated through different ends of emotion and every night it dies and is resurrected in the morning. Then she proceeds to show us a picture of what the alien she described looked like? I’m not sure if the illustrations are supposed to be her imagined ASI system or aesthetics drawings to the text. 

For some people imagining a world with ASI as a real possibility is horrifying and “aesthetically repulsive” because their mind automatically goes to a place of world destruction. I used to think that before reading this text. All of the theories mentioned are very creative and are scenarios I wouldn’t have ever sat down and thought about willingly because well it’s scary to think about a world where humans aren’t the main superintelligence. To not be afraid of the unknown future we have to try to understand it and that feels strange to be trying to understand something that is not yet here. But thinking about ASI before it exists provides us with spaces of new ways of thinking and feeling. Rationally, she points out that an ASI with world domination as a primary goal wouldn’t be a very “productive or fun mode”. In order to stray away from this destructive threating ASI, we must stop anthropomorphizing it. Which means to stop imagining it with human form and personality. “Think of an AI as a force of nature like a star system or hurricane – something strong, but indifferent. If its main goal is to win at chess it will be ruthless in achieving that goal but is limited to the chessboard. But if the AI’s goal is something larger in the physically world, we must be very specific about the goals we give it.”

That quote made me feel better about the very idea of an ASI future and I’ve always thought well it’s up to us to program them so if we didn’t want them to turn bad they wouldn’t right? I rethought this when I read the Sovereign section where the example of a satiation in which in an ASI is to make a decision for the greater good and humans are not favored. “Even if we made the sovereign, its choices have nothing to do with us.” I feel as though no matter what the goal of the ASI is they can grow and improve on that idea and it could possibly change and if we keep pushing the Earth to extinction as we are doing now, ASI will be the species to continue to sustain the Earth and we will no longer be needed.
