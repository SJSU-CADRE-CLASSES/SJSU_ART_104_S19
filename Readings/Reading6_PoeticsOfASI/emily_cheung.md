## Reading 6
In Nora N. Khan’s article, “Towards a Poetics of Artificial Super intelligence”, she starts off by asking the audience to imagine what it would be like to have ASI (artificial super intelligence), such as a mechanic mind. When artificial intelligence is mentioned, the thoughts of machines and robots as smart as humans come to my mind. These machines are able to accomplish what humans do and react to. Khan describes ASI as “an intellect that exceeds all the smartest, most capable human beings in every field, in abstract reasoning and social manoeuvring and creative experimentation, by unfathomable degrees” (Khan), portraying ASI like some kind of robot. Khan also introduces Artificial General Intelligence (AGI) and interprets it as intelligence that all humans can do, such as the basics of reading and learning. It is interesting to think about how Khan describes these different intelligences as things we will never actually fully understand because there are so many concepts and thoughts about it. In her article, Khan introduces Cyberneticist, Kevin Warwick who asked a question about how one can reason what a machine is thinking or how one can understand a machine. There doesn’t actually seem to be a way humans can fully interpret what a machine is actually thinking inside 24/7. 
Machines today are so advanced and so popular and useful today that we often seem to have to develop a language or an intelligence for it. Khan mentions how “we struggle more and more to define ourselves in relation to machine intelligences” (Khan), stating how we are so attached to these machines now, using them for work or for entertainment. Since AI has not been thoroughly refined in our society, we find ourselves constantly trying to come up with different ways to describe these machines that are continuously advancing. Khan continues to describe AI (Artificial Intelligence) in her article as “gives us a sense of what is of what is possible [and how] they form the outline of our future” (Khan), proving how AI is not fully developed yet. 
Khan also introduces a philosopher, Nick Bostrom, who talks about different possibilities of what AI would look like by “[relying] on metaphors to propel his abstractions [with his] experiments” (Khan). He believes metaphors are very vital factors to the idea and power of ASI. Khan lists out the different metaphors Bostrom talks about, such as hurricane, architect, sovereign, star system, etc. 
The one I found most interesting was hurricane because of how perfectly accurate it sounds. When the word “hurricane” is mentioned, it sounds like a brutal and horrifying experience. Bostrom’s simple, yet heavy statement of “how potentially destructive a true ASI could be” (Khan) struck me because as we see ASI as something beneficial, but we never see the harmful side of it. It is interesting to think that something so beneficial to us can also harm us. As Bostrom continues describing the metaphor of the hurricane, he talks about how humans predict and prepare for a hurricane, which is similar to how we observe ASI and we can prepare for it.  
