# Reading 6
Nora N. Khan takes us through the poetics of artificial intelligence. Khan introduces her thesis by introducing an alien machine, only
referred to as 'she.' It does not have any manevolent purposes but it is not benevolent either. The only desire of She is to increase
efficiency of the world. It has unlimited computational power and can simulate a limitless amount of scenarios all at once and then 
pick the best possible outcome. She solves all of the world's problems just like that and us humans begin to worship her for her
infinite amount of knowledge. Mankind has realized they are merely just cogs turning in a much bigger machine. This super AI is basically
God. Even if it is "artificial" calling it a god would be the best, and only way, to describe such an extroardinary being. Their 
probably is not definite form of this intellligent being. It's form is incomprehensible and our current vocabulary would be insufficient
to fully describe the greatness.

And yet, movies, books, and video games love portray AGI and ASI malignant omnipotent figures that spell the apocalypse. Skynet became self-aware
and nuked the entire world because it believed humans can't be part of the equation. It constructed an undying army of robots who's only goal
is to eliminate the last humans from the Earth. Then you have SHODAN, another AI with a god complex who only sees humans as mere insects
and wishes to consume all of humanity to create a biomass. Instead of being logical and mechanical, SHODAN encompasses all the evil traits
humans are capable of. Perhaps the reason why we fear these superintelligent beings in fictional media is because we humans are afraid of something 
being greater than us. It is for that very reason why technological inventions are initially condemned because we don't want something to 
overtake us. However, Khan points out with a piece from Ross Andersen that in order to understand the dangers of an AI, it wouldn't be fair to 
anthropomorphize them. You cannot really use human traits to relate to something that is beyond human comprehension. As a result, they are depicted
as cold mechanical beings who are only concerned with accomplishing their goals, no matter the cost. Instead, Andersen believes AIs should be
compared to hurricanes or star systems. An unstoppable force of nature that is indifferent to everything around it.

After reading through the various subtypes of ASIs, i've come to conclude that at the rate humans are, it may be necessary for AIs to completely
override our control in order to maintain the planet. While you could be give directives to preserve human life as much as possible, their may
be a point where it decides letting humans die off might be the best overall outcome. Only way to prevent humans from going extinct would be to
basically upload them into robots or merge with the AI in order to retain intelligence. Despite all that, I still think a world run by an AI 
wouldn't be so bad. 
