The idea of AI sounds cool… but as movies and games will tell me, it’s ultimately going to go a whole different direction that was originally intended.
I pretty much agreed with what the article was saying. Artificial intelligence thinks on a whole other level than biological brains are capable of; they can compute at the speed of light and solve abstract problems with a snap. To think of artificial intelligence having administrative power over living humans, making decisions not on a lifetime of moral insight but on decisions coded into its program, is something really scary to think about. 
Don’t get me wrong, I’m not totally opposed to AI- they’re very cool, for one thing, and they are also beings that we are creating from the ground up instead of nurturing biologically. Then we get to see what makes artificial intelligence has to pit against biological intelligence, something that has been continuously been refined over billions of years. I think AI would be pretty efficient in calculating monetary totals in business- computers are doing that already- or refining models for medical and emergency protocols, maybe. They’d be able to process calculations much faster than humans can do, and enable us to process other technologies much faster and possibly give us better quality of life. 
	The moral implications of creating artificial intelligence, however- video games and movies have beat developers to the punch by asking the big questions. Is artificial intelligence a new form of life? Are they considered people, given sentience? What is the nature of this master/machine relationship, and in the future, should they be given extended rights? When I think about super-intelligent AI, games like Mass Effect and Detroit: Become Human come to mind. The Mass Effect trilogy was all about fighting a war against AI, a sentient people who had forsaken their original creators and driven them off their home planet. By the third game, it’s established that they had only fought in self-defense, as they were beginning to be destroyed by their creators because they had started asking questions about their own existence. The player has a choice whether or not to destroy them or make peace with them, but at that point it’s making a narrative instead of focusing on the creation of AI themselves. 
	Detroit: Become Human is a game based entirely on this premise, however; androids created by a company called CyberLife has become the dominant new technology on the market. Super-intelligent androids who can perform thousands of tasks, from household chores to medical care to physical labor, have become prevalent in the city of Detroit and across the nation. Even with their new popularity, however, their capabilities have caused the skyrocket of unemployment as AI perform their tasks much more efficiently than humans, and public opinion of them is very low. This, I feel is the much more likely scenario in the future compared to Mass Effect. Rather than them waging physical war with laser guns, there would be a displacement in societal structures themselves. AI, being vastly intelligent beings who process on a much higher level than human brains, would cause a huge displacement if introduced to human society at administrative levels. They literally make decisions inside their own vacuum; if I had to trust a human or an AI to display empathy, I’d take the human. There are things about biological thinking that we don’t even fully understand yet, and here we are making artificial thinking. 
	However, that’s just my understanding given the level of AI that are developed now; if AI had displayed the level of intelligence, thinking, and even empathy in the video games I’ve seen, then I’d feel more kindly and open to them, because at that point they are literally their own people with their own minds. But now, it’s like trusting a child to file my taxes. 
